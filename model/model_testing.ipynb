{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNjdblU+O6JGUaR5iOfgoDZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doomsday4/Heat-Transfer-in-Advanced-Manufacturing-using-PINN/blob/main/model_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cajAmpzj4sx-",
        "outputId": "79e1fe61-bf5d-4e5e-f857-bdd5b718961d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-6374083f4725>:144: DeprecationWarning: `interp2d` is deprecated!\n",
            "`interp2d` is deprecated in SciPy 1.10 and will be removed in SciPy 1.13.0.\n",
            "\n",
            "For legacy code, nearly bug-for-bug compatible replacements are\n",
            "`RectBivariateSpline` on regular grids, and `bisplrep`/`bisplev` for\n",
            "scattered 2D data.\n",
            "\n",
            "In new code, for regular grids use `RegularGridInterpolator` instead.\n",
            "For scattered data, prefer `LinearNDInterpolator` or\n",
            "`CloughTocher2DInterpolator`.\n",
            "\n",
            "For more details see\n",
            "`https://scipy.github.io/devdocs/notebooks/interp_transition_guide.html`\n",
            "\n",
            "  ftem = interp2d(x, t, Exact.T)\n",
            "<ipython-input-8-6374083f4725>:158: DeprecationWarning:         `interp2d` is deprecated!\n",
            "        `interp2d` is deprecated in SciPy 1.10 and will be removed in SciPy 1.13.0.\n",
            "\n",
            "        For legacy code, nearly bug-for-bug compatible replacements are\n",
            "        `RectBivariateSpline` on regular grids, and `bisplrep`/`bisplev` for\n",
            "        scattered 2D data.\n",
            "\n",
            "        In new code, for regular grids use `RegularGridInterpolator` instead.\n",
            "        For scattered data, prefer `LinearNDInterpolator` or\n",
            "        `CloughTocher2DInterpolator`.\n",
            "\n",
            "        For more details see\n",
            "        `https://scipy.github.io/devdocs/notebooks/interp_transition_guide.html`\n",
            "\n",
            "  X_tem = ftem(X_f[:, 0], 0).flatten()[:, None]\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 513610.9637938071\n",
            "Epoch: 100, Loss: 2557.692966414559\n",
            "Epoch: 200, Loss: 47.284276287188106\n",
            "Epoch: 300, Loss: 82.50186519952989\n",
            "Epoch: 400, Loss: 394.02291045777\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6374083f4725>\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training time: %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6374083f4725>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, learning_rate)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    973\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    974\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1216\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1217\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1396\u001b[0m                            run_metadata)\n\u001b[1;32m   1397\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1400\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1383\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1386\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1476\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1477\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1478\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1479\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m                                             run_metadata)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "# import tensorflow_probability as tfp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "from pyDOE import lhs\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import time\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from scipy import interpolate\n",
        "from scipy.interpolate import interp2d\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class SolidificationPINN:\n",
        "    def __init__(self, x0, tem0, tb, X_f, X_tem, layers, lb, ub):\n",
        "        self.lb = lb\n",
        "        self.ub = ub\n",
        "\n",
        "        self.x0 = x0\n",
        "        self.tem0 = tem0\n",
        "        self.tb = tb\n",
        "        self.x_f = X_f[:, 0:1]\n",
        "        self.t_f = X_f[:, 1:2]\n",
        "        self.tem_f = X_tem\n",
        "\n",
        "        self.layers = layers\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "\n",
        "        self.x0_tf = tf.convert_to_tensor(x0, dtype=tf.float64)\n",
        "        self.tem0_tf = tf.convert_to_tensor(tem0, dtype=tf.float64)\n",
        "        self.tb_tf = tf.convert_to_tensor(tb, dtype=tf.float64)\n",
        "        self.x_f_tf = tf.convert_to_tensor(self.x_f, dtype=tf.float64)\n",
        "        self.t_f_tf = tf.convert_to_tensor(self.t_f, dtype=tf.float64)\n",
        "        self.tem_f_tf = tf.convert_to_tensor(self.tem_f, dtype=tf.float64)\n",
        "\n",
        "        self.sess = tf.compat.v1.Session()\n",
        "\n",
        "        self.learning_rate = tf.compat.v1.placeholder(tf.float64, shape=[])\n",
        "        self.tem0_pred = self.net_uv(self.x0_tf, tf.zeros_like(self.x0_tf))\n",
        "        self.f_u_pred = self.net_f_uv(self.x_f_tf, self.t_f_tf)\n",
        "\n",
        "        self.loss = tf.reduce_mean(tf.square(self.tem0_tf - self.tem0_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.f_u_pred))\n",
        "\n",
        "        self.optimizer = tf.compat.v1.train.AdamOptimizer(self.learning_rate)\n",
        "        self.train_op = self.optimizer.minimize(self.loss)\n",
        "\n",
        "        init = tf.compat.v1.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    def initialize_NN(self, layers):\n",
        "        weights = []\n",
        "        biases = []\n",
        "        for l in range(len(layers) - 1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l + 1]])\n",
        "            b = tf.Variable(tf.zeros([1, layers[l + 1]], dtype=tf.float64), dtype=tf.float64)\n",
        "            weights.append(W)\n",
        "            biases.append(b)\n",
        "        return weights, biases\n",
        "\n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]\n",
        "        xavier_stddev = np.sqrt(2 / (in_dim + out_dim))\n",
        "        return tf.Variable(tf.random.truncated_normal([in_dim, out_dim], stddev=xavier_stddev, dtype=tf.float64), dtype=tf.float64)\n",
        "\n",
        "    def forward_pass(self, H):\n",
        "        for l in range(len(self.layers) - 2):\n",
        "            W = self.weights[l]\n",
        "            b = self.biases[l]\n",
        "            H = tf.nn.swish(tf.add(tf.matmul(H, W), b))\n",
        "        W = self.weights[-1]\n",
        "        b = self.biases[-1]\n",
        "        H = tf.add(tf.matmul(H, W), b)\n",
        "        return H\n",
        "\n",
        "    def net_uv(self, x, t):\n",
        "        X = tf.concat([x, t], axis=1)\n",
        "        uv = self.forward_pass(X)\n",
        "        return uv\n",
        "\n",
        "    def net_f_uv(self, x, t):\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            tape.watch(x)\n",
        "            tape.watch(t)\n",
        "            uv = self.net_uv(x, t)\n",
        "            uv_x = tape.gradient(uv, x)\n",
        "        uv_t = tape.gradient(uv, t)\n",
        "        uv_xx = tape.gradient(uv_x, x)\n",
        "        del tape\n",
        "        f_uv = uv_t - uv_xx\n",
        "        return f_uv\n",
        "\n",
        "    def train(self, epochs, learning_rate):\n",
        "        for epoch in range(epochs):\n",
        "            self.sess.run(self.train_op, feed_dict={self.learning_rate: learning_rate})\n",
        "            if epoch % 100 == 0:\n",
        "                loss_value = self.sess.run(self.loss, feed_dict={self.learning_rate: learning_rate})\n",
        "                print(f'Epoch: {epoch}, Loss: {loss_value}')\n",
        "\n",
        "    def predict(self, X_star):\n",
        "        X_star = tf.convert_to_tensor(X_star, dtype=tf.float64)\n",
        "        tem_star = self.sess.run(self.net_uv(X_star[:, 0:1], X_star[:, 1:2]))\n",
        "        ftem_star = self.sess.run(self.net_f_uv(X_star[:, 0:1], X_star[:, 1:2]))\n",
        "        return tem_star, ftem_star\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from scipy.interpolate import interp2d\n",
        "import time\n",
        "from pyDOE import lhs\n",
        "import tensorflow as tf\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    noise = 0.0\n",
        "\n",
        "    ltem = 298.15\n",
        "    utem = 973.15\n",
        "    eps = 0.02\n",
        "\n",
        "    # Domain bounds\n",
        "    lb = np.array([-0.4, 5.0])\n",
        "    ub = np.array([0.4, 10.0])\n",
        "\n",
        "    N0 = 300\n",
        "    N_b = 100\n",
        "    N_f = 10000\n",
        "    num_hidden = 8\n",
        "    layers = [2] + num_hidden * [200] + [1]\n",
        "\n",
        "    data = scipy.io.loadmat('thermal_fine.mat')\n",
        "    x = data['x'].flatten()[:, None]\n",
        "    t = data['tt'].flatten()[:, None]\n",
        "    Exact = data['Tem']\n",
        "    Exact_tem = np.real(Exact)\n",
        "\n",
        "    ftem = interp2d(x, t, Exact.T)\n",
        "\n",
        "    X, T = np.meshgrid(x, t)\n",
        "    X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
        "\n",
        "    idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
        "    x0 = x[idx_x, :]\n",
        "    tem0 = Exact_tem[idx_x, 0:1]\n",
        "\n",
        "    idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
        "    tb = t[idx_t, :]\n",
        "\n",
        "    X_f = lb + (ub - lb) * lhs(2, N_f)\n",
        "    X_f = X_f[np.argsort(X_f[:, 0])]\n",
        "    X_tem = ftem(X_f[:, 0], 0).flatten()[:, None]\n",
        "\n",
        "    model = SolidificationPINN(x0, tem0, tb, X_f, X_tem, layers, lb, ub)\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.train(epochs=1000, learning_rate=0.01)\n",
        "    elapsed = time.time() - start_time\n",
        "    print('Training time: %.4f' % (elapsed))\n",
        "\n",
        "    tem_pred, ftem_pred = model.predict(X_star)\n",
        "    np.savetxt('predict_xT.txt', X_star)\n",
        "    np.savetxt('predict_tem.txt', tem_pred)\n",
        "    np.savetxt('predict_ftem.txt', ftem_pred)"
      ]
    }
  ]
}